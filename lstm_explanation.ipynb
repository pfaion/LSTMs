{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory - Sample Implementation and Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all imports for the whole notebook\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial will provide an overview over the concept of LSTMs by providing a Python implementation that does not rely on any framework specifically for neural networks. Thereby all necessary code to implement the LSTM-Cells will be shown. In order to get insight into how LSTMs work internally, a small network will be trained on a simple example task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task description\n",
    "\n",
    "The task for this LSTM network will be a simple sequence prediction task. Elements of the sequence will be letters from a subset of the alphabet. The sequences are constructed as follows:\n",
    "\n",
    "1. They start with a small sequence of random characters with varying length.\n",
    "2. Then there is a marker letter, that will not be used anywhere else in the whole sequence.\n",
    "3. A random letter follows, which will be called **target**.\n",
    "4. Another larger random sequence with varying length follows.\n",
    "5. After this, there is a second marker letter, that will also not be used anywhere else in the whole sequence.\n",
    "6. The final character is again the **target** letter.\n",
    "\n",
    "In order to learn the task, the network must recognize the marker letters in order to open/close the gates of the memory cells appropriately. The **target** letter then has to be stored in the network until the second marker appeares. Overall performance of the task can be measured by calculating the average prediction error for the last character in every sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "At first we have to setup the general environment for the task, like the list of letters to be used, the markers, and similar initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers: ['a', 'b']\n",
      "Letters: ['c', 'd']\n"
     ]
    }
   ],
   "source": [
    "# marker letters\n",
    "mark1 = 'a'\n",
    "mark2 = 'b'\n",
    "\n",
    "# nums\n",
    "num_random_letters = 2\n",
    "num_letters = num_random_letters + 2\n",
    "\n",
    "# random letters\n",
    "all_letters = list(string.ascii_lowercase)\n",
    "letters = all_letters[2:num_letters]\n",
    "\n",
    "print(\"Markers:\", [mark1, mark2])\n",
    "print(\"Letters:\", letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we need a function that can sample us a list of letters with length in a specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomSequenceSample(minlength, maxlength):\n",
    "    length = random.randint(minlength, maxlength)\n",
    "    for _ in range(length):\n",
    "        rand_idx = random.randint(0, len(letters)-1)\n",
    "        yield letters[rand_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample 1 : ['c', 'd', 'c', 'd', 'd', 'c', 'd', 'c', 'c', 'c', 'c', 'd']\n",
      "Test sample 2 : ['d', 'd', 'c', 'c', 'd', 'd', 'c', 'c', 'c', 'd', 'c', 'd', 'd', 'd']\n",
      "Test sample 3 : ['c', 'd', 'd', 'd', 'd', 'c', 'c', 'c', 'c', 'c']\n",
      "Test sample 4 : ['c', 'd']\n",
      "Test sample 5 : ['d', 'd', 'd']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Test sample\", i+1, \":\", list(randomSequenceSample(1, 15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to put those random sequence samples together with the markers and target letters in order to get a problem sequence as decribed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSequence(premin, premax, midmin, midmax):\n",
    "    target_i = random.randint(0, len(letters)-1)\n",
    "    target = letters[target_i]\n",
    "    pre = list(randomSequenceSample(premin, premax))\n",
    "    mid = list(randomSequenceSample(midmin, midmax))\n",
    "    return pre + [mark1, target] + mid + [mark2, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a few sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence test 1 : ['c', 'c', 'c', 'a', 'c', 'd', 'd', 'b', 'c']\n",
      "Sequence test 2 : ['c', 'c', 'd', 'a', 'c', 'c', 'b', 'c']\n",
      "Sequence test 3 : ['c', 'a', 'c', 'c', 'd', 'c', 'b', 'c']\n",
      "Sequence test 4 : ['c', 'c', 'c', 'a', 'c', 'c', 'c', 'c', 'b', 'c']\n",
      "Sequence test 5 : ['a', 'd', 'd', 'd', 'd', 'c', 'c', 'b', 'd']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Sequence test\", i+1, \":\", generateSequence(0,3,1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def formatSequenceToPrint(s):\n",
    "    new_s = []\n",
    "    check_next = False\n",
    "    for item in s:\n",
    "        if item == mark1 or item == mark2:\n",
    "            item = '_'\n",
    "            check_next = True\n",
    "        elif check_next == True:\n",
    "            item = item.upper()\n",
    "            check_next = False\n",
    "        new_s.append(item)\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence test 1 : ['_', 'C', 'c', 'c', 'c', 'd', '_', 'C']\n",
      "Sequence test 2 : ['d', 'd', '_', 'C', 'c', 'd', 'c', 'c', '_', 'C']\n",
      "Sequence test 3 : ['d', 'c', '_', 'D', 'd', 'c', 'd', '_', 'D']\n",
      "Sequence test 4 : ['d', 'c', 'd', '_', 'D', 'c', 'c', 'c', 'c', 'd', '_', 'D']\n",
      "Sequence test 5 : ['d', '_', 'D', 'c', 'c', 'c', 'd', '_', 'D']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Sequence test\", i+1, \":\", formatSequenceToPrint(generateSequence(0,3,1,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letterToCategorical(l):\n",
    "    lst = [0.0] * num_letters\n",
    "    lst[all_letters.index(l)] = 1.0\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical of 'a': [1.0, 0.0, 0.0, 0.0]\n",
      "Categorical of 'e': [0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Categorical of 'a':\", letterToCategorical(\"a\"))\n",
    "print(\"Categorical of 'e':\", letterToCategorical(\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequenceToCategoricalNumpy(seq):\n",
    "    new_s = []\n",
    "    for letter in seq:\n",
    "        new_s.append(letterToCategorical(letter))\n",
    "    return np.array(new_s).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy categorical matrix of ['a', 'b', 'c']:\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy categorical matrix of ['a', 'b', 'c']:\")\n",
    "print(sequenceToCategoricalNumpy(list(\"abc\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catSequenceToInputOutputLists(seq):\n",
    "    inpList = []\n",
    "    outList = []\n",
    "    for i in range(seq.shape[1] - 1):\n",
    "        inpList.append(seq[:,i,None])\n",
    "        outList.append(seq[:,i+1,None])\n",
    "    return (inpList, outList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inpOutSequenceGenerator(n, premin, premax, midmin, midmax):\n",
    "    for i in range(n):\n",
    "        seq = generateSequence(premin, premax, midmin, midmax)\n",
    "        catSeq = sequenceToCategoricalNumpy(seq)\n",
    "        yield catSequenceToInputOutputLists(catSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gate:\n",
    "    def __init__(self, inpDim, bias):\n",
    "        self.inpDim = inpDim\n",
    "        self.W = np.random.rand(1, self.inpDim) * 0.2 - 0.1\n",
    "        self.deltaW = np.zeros(self.W.shape)\n",
    "        self.W[0,0] = bias\n",
    "        self.f = sigmoid\n",
    "        self.f_deriv = sigmoid_deriv\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        self.inp = inp\n",
    "        self.netInp = self.W @ inp\n",
    "        self.y = self.f(self.netInp)\n",
    "        return self.y\n",
    "    \n",
    "    def update(self):\n",
    "        self.W += self.deltaW\n",
    "        self.deltaW = np.zeros(self.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutGate(Gate):\n",
    "    def backward(self, error, learningRate):\n",
    "        self.grad = self.f_deriv(self.netInp) * error\n",
    "        self.deltaW += learningRate * (self.grad @ self.inp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InpGate(Gate):\n",
    "    def backward(self, grad, learningRate):\n",
    "        self.deltaW += learningRate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ForgetGate(Gate):\n",
    "    def backward(self, grad, learningRate):\n",
    "        self.deltaW += learningRate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMCell:\n",
    "    def __init__(self, inpDim):\n",
    "        self.inpDim = inpDim\n",
    "        \n",
    "        # 1. Initialize cell specific parts\n",
    "        \n",
    "        self.state = np.array([[0.0]])\n",
    "        self.W = np.random.rand(1, self.inpDim) * 0.2 - 0.1\n",
    "        self.deltaW = np.zeros(self.W.shape)\n",
    "        self.g = sigmoid\n",
    "        self.g_deriv = sigmoid_deriv\n",
    "        self.y = np.array([[0.0]])\n",
    "        \n",
    "        # 2. Initialize gates\n",
    "        \n",
    "        # Gate input is one larger than cell input, because of the peephole connections.\n",
    "        gateDim = self.inpDim + 1\n",
    "        # Biases for the gates were taken from the papers. They proved most successfull.\n",
    "        inpBias = 0.0\n",
    "        forgetBias = -2.0\n",
    "        outBias = 2.0\n",
    "        \n",
    "        # now create the objects\n",
    "        self.inpGate = InpGate(gateDim, inpBias)\n",
    "        self.forgetGate = ForgetGate(gateDim, forgetBias)\n",
    "        self.outGate = OutGate(gateDim, outBias)\n",
    "        \n",
    "        # 3. Initialize derivatives\n",
    "        \n",
    "        self.stateDerivWRTCellWeights = np.zeros(self.W.shape)\n",
    "        self.stateDerivWRTInpGateWeights = np.zeros(self.inpGate.W.shape)\n",
    "        self.stateDerivWRTForgetGateWeights = np.zeros(self.forgetGate.W.shape)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        self.inp = inp\n",
    "        self.netInp = self.W @ inp\n",
    "        \n",
    "        inpWPrevPeep = np.append(inp, self.state, axis = 0)\n",
    "        self.inpGate.forward(inpWPrevPeep)\n",
    "        self.forgetGate.forward(inpWPrevPeep)\n",
    "        \n",
    "        # update derivatives\n",
    "        self.stateDerivWRTCellWeights *= self.forgetGate.y\n",
    "        self.stateDerivWRTCellWeights += self.g_deriv(self.netInp) * self.inpGate.y * inp.T\n",
    "        \n",
    "        self.stateDerivWRTInpGateWeights *= self.forgetGate.y\n",
    "        self.stateDerivWRTInpGateWeights += self.g(self.netInp) * self.inpGate.f_deriv(self.inpGate.netInp) * inpWPrevPeep.T\n",
    "        \n",
    "        self.stateDerivWRTForgetGateWeights *= self.forgetGate.y\n",
    "        self.stateDerivWRTForgetGateWeights += self.state * self.forgetGate.f_deriv(self.forgetGate.netInp) * inpWPrevPeep.T\n",
    "        \n",
    "        \n",
    "        self.state = self.forgetGate.y * self.state + self.inpGate.y * self.g(self.netInp)\n",
    "        \n",
    "        inpWPostPeep = np.append(inp, self.state, axis = 0)\n",
    "        self.outGate.forward(inpWPostPeep)\n",
    "        \n",
    "        self.y = self.outGate.y * self.state\n",
    "        \n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, error, learningRate):\n",
    "        \n",
    "        outGateError = self.state * error\n",
    "        self.outGate.backward(outGateError, learningRate)\n",
    "        \n",
    "        internalError = self.outGate.y * error\n",
    "        \n",
    "        self.deltaW += learningRate * internalError * self.stateDerivWRTCellWeights\n",
    "        \n",
    "        inpGateError = internalError * self.stateDerivWRTInpGateWeights\n",
    "        self.inpGate.backward(inpGateError, learningRate)\n",
    "        \n",
    "        forgetGateError = internalError * self.stateDerivWRTForgetGateWeights\n",
    "        self.forgetGate.backward(forgetGateError, learningRate)\n",
    "        \n",
    "    def update(self):\n",
    "        self.W += self.deltaW\n",
    "        self.deltaW = np.zeros(self.W.shape)\n",
    "        \n",
    "        self.outGate.update()\n",
    "        self.inpGate.update()\n",
    "        self.forgetGate.update()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([[0.0]])\n",
    "        self.stateDerivWRTCellWeights = np.zeros(self.W.shape)\n",
    "        self.stateDerivWRTInpGateWeights = np.zeros(self.inpGate.W.shape)\n",
    "        self.stateDerivWRTForgetGateWeights = np.zeros(self.forgetGate.W.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OutputLayer:\n",
    "    def __init__(self, inpDim, outDim):\n",
    "        self.inpDim = inpDim\n",
    "        self.outDim = outDim\n",
    "        \n",
    "        self.W = np.random.rand(self.outDim, self.inpDim) * 0.2 - 0.1\n",
    "        self.deltaW = np.zeros(self.W.shape)\n",
    "        self.f = sigmoid\n",
    "        self.f_deriv = sigmoid_deriv\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        self.inp = inp\n",
    "        self.netInp = self.W @ inp\n",
    "        self.y = self.f(self.netInp)\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, target, learningRate):\n",
    "        #self.error = np.square(self.y - target)\n",
    "        self.error = self.y - target\n",
    "        self.grad = self.f_deriv(self.netInp) * self.error\n",
    "        self.deltaW += learningRate * (self.grad @ self.inp.T)\n",
    "    \n",
    "    def update(self):\n",
    "        self.W += self.deltaW\n",
    "        self.deltaW = np.zeros(self.W.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork:\n",
    "    def __init__(self, inpDim, outDim, n_cells):\n",
    "        self.inpDim = inpDim\n",
    "        self.outDim = outDim\n",
    "        self.n_cells = n_cells\n",
    "        \n",
    "        self.biasUnit = np.array([[1]])\n",
    "        self.inpAndHiddenDimWBias = self.inpDim + n_cells + 1\n",
    "        self.n_cellsWBias = 1 + self.n_cells\n",
    "        \n",
    "        self.cells = [LSTMCell(self.inpAndHiddenDimWBias) for _ in range(self.n_cells)]\n",
    "        self.outLayer = OutputLayer(self.n_cellsWBias, self.outDim)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        inpAndHidden = np.append(inp, self.hiddenLayerState(), axis = 0)\n",
    "        inpAndHiddenWBias = np.append(inpAndHidden, self.biasUnit, axis = 0)\n",
    "        \n",
    "        for cell in self.cells:\n",
    "            cell.forward(inpAndHiddenWBias)\n",
    "            \n",
    "        stateWBias = np.append(self.hiddenLayerState(), self.biasUnit, axis = 0)\n",
    "        \n",
    "        self.outLayer.forward(stateWBias)\n",
    "        \n",
    "        return self.outLayer.y\n",
    "    \n",
    "    def hiddenLayerState(self):\n",
    "        return np.array([[cell.y[0,0] for cell in self.cells]]).T\n",
    "    \n",
    "    def cellStates(self):\n",
    "        return np.array([[cell.state[0,0] for cell in self.cells]]).T\n",
    "        \n",
    "    def backward(self, target, learningRate):\n",
    "        self.outLayer.backward(target, learningRate)\n",
    "        self.error = np.sum(np.square(self.outLayer.y - target))\n",
    "        \n",
    "        outErrors = self.outLayer.W.T @ self.outLayer.grad\n",
    "        outErrorsWOBias = outErrors[:-1]\n",
    "        \n",
    "        for idx, cell in enumerate(self.cells):\n",
    "            cell.backward(outErrorsWOBias[idx], learningRate)\n",
    "        \n",
    "    def update(self):\n",
    "        self.outLayer.update()\n",
    "        for cell in self.cells:\n",
    "            cell.update()\n",
    "    \n",
    "    def resetCells(self):\n",
    "        for cell in self.cells:\n",
    "            cell.reset()\n",
    "            \n",
    "    def train(self, inpOutList, batchSize, learningRate):\n",
    "        for sample_i, (inpSeq, outSeq) in enumerate(inpOutList):\n",
    "            self.resetCells()\n",
    "            for i in range(len(inpSeq)):\n",
    "                inp = inpSeq[i]\n",
    "                out = outSeq[i]\n",
    "                self.forward(inp)\n",
    "                self.backward(out, learningRate)\n",
    "                if (i+1)%batchSize == 0 or i == len(inpSeq) - 1:\n",
    "                    self.update()\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = LSTMNetwork(num_letters,num_letters,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpOutList = inpOutSequenceGenerator(500,0,0,0,0)\n",
    "n.train(inpOutList, batchSize = 1, learningRate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99991166],\n",
       "       [ 0.9997975 ],\n",
       "       [ 0.99984277],\n",
       "       [ 0.99981824]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.outLayer.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
